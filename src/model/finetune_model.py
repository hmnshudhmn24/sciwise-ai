import yaml

def finetune(cfg_path='src/config/model_config.yaml'):
    print('Placeholder finetune function. Load dataset, attach LoRA adapters, and run Trainer here.')
